{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Unsupervised Learning - K-Means Clustering\n",
    "\n",
    "**Objective**: Discover natural groupings of countries based on macroeconomic indicators and compare with actual credit ratings.\n",
    "\n",
    "**Questions to answer**:\n",
    "1. Do countries naturally group by risk level?\n",
    "2. How many distinct risk profiles exist?\n",
    "3. Do discovered clusters correspond to credit ratings?\n",
    "4. Which countries are outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/processed/merged_dataset_labels.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for clustering\n",
    "identifiers = df[['Country', 'Year']]\n",
    "labels = df['Credit_Rating_Label']\n",
    "X = df.drop(['Country', 'Year', 'Credit_Rating_Label'], axis=1)\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "print(f\"Features for clustering: {feature_names}\")\n",
    "print(f\"Number of observations: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Elbow Method - Finding Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features (important for K-Means)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Features normalized with StandardScaler\")\n",
    "print(f\"Mean: {X_scaled.mean(axis=0).round(2)}\")\n",
    "print(f\"Std: {X_scaled.std(axis=0).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different K values\n",
    "k_range = [2, 3, 4, 5, 6, 7, 8]\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    inertia = kmeans.inertia_\n",
    "    silhouette = silhouette_score(X_scaled, clusters)\n",
    "    \n",
    "    inertias.append(inertia)\n",
    "    silhouette_scores.append(silhouette)\n",
    "    \n",
    "    print(f\"K={k}: Inertia={inertia:.2f}, Silhouette={silhouette:.4f}\")\n",
    "\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\n✓ Optimal K = {optimal_k} (Silhouette Score: {max(silhouette_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Elbow Method\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Inertia\n",
    "axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Inertia', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Elbow Method - Inertia', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axvline(x=optimal_k, color='red', linestyle='--', alpha=0.5, label=f'Optimal K={optimal_k}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Silhouette Score\n",
    "axes[1].plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Number of Clusters (K)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Silhouette Score by K', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Good threshold (0.5)')\n",
    "axes[1].axvline(x=optimal_k, color='red', linestyle='--', alpha=0.5, label=f'Optimal K={optimal_k}')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Means Clustering with Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means with optimal K\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "inertia = kmeans.inertia_\n",
    "silhouette = silhouette_score(X_scaled, clusters)\n",
    "silhouette_vals = silhouette_samples(X_scaled, clusters)\n",
    "\n",
    "print(f\"K-Means Clustering (K={optimal_k})\")\n",
    "print(f\"  Inertia: {inertia:.2f}\")\n",
    "print(f\"  Silhouette Score: {silhouette:.4f}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(pd.Series(clusters).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Country': identifiers['Country'],\n",
    "    'Year': identifiers['Year'],\n",
    "    'Credit_Rating_Label': labels,\n",
    "    'Cluster': clusters,\n",
    "    'Silhouette_Score': silhouette_vals\n",
    "})\n",
    "\n",
    "# Add original features\n",
    "for col in feature_names:\n",
    "    results_df[col] = df[col].values\n",
    "\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Profiles Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each cluster\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = results_df[results_df['Cluster'] == cluster_id]\n",
    "    n_obs = len(cluster_data)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLUSTER {cluster_id}: {n_obs} observations\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Mean values for each feature\n",
    "    print(\"\\nMean Economic Indicators:\")\n",
    "    for feature in feature_names:\n",
    "        mean_val = cluster_data[feature].mean()\n",
    "        print(f\"  {feature:20s}: {mean_val:8.2f}\")\n",
    "    \n",
    "    # Rating distribution\n",
    "    print(\"\\nCredit Rating Distribution:\")\n",
    "    rating_counts = cluster_data['Credit_Rating_Label'].value_counts().head(5)\n",
    "    for rating, count in rating_counts.items():\n",
    "        print(f\"  {rating:10s}: {count:3d} ({count/n_obs*100:.1f}%)\")\n",
    "    \n",
    "    # Sample countries (most recent year)\n",
    "    latest_year = cluster_data['Year'].max()\n",
    "    recent_countries = cluster_data[cluster_data['Year'] == latest_year]['Country'].tolist()[:10]\n",
    "    print(f\"\\nSample Countries ({latest_year}):\")\n",
    "    print(f\"  {', '.join(recent_countries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster profiles\n",
    "cluster_profiles = []\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = results_df[results_df['Cluster'] == cluster_id]\n",
    "    profile = {'Cluster': f'Cluster {cluster_id}'}\n",
    "    for feature in feature_names:\n",
    "        profile[feature] = cluster_data[feature].mean()\n",
    "    cluster_profiles.append(profile)\n",
    "\n",
    "profiles_df = pd.DataFrame(cluster_profiles)\n",
    "profiles_df = profiles_df.set_index('Cluster')\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(profiles_df.T, annot=True, fmt='.2f', cmap='RdYlGn_r', center=0, \n",
    "            cbar_kws={'label': 'Mean Value'})\n",
    "plt.title(f'Cluster Profiles - Mean Economic Indicators (K={optimal_k})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison with Credit Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group ratings into categories\n",
    "def rating_to_category(rating):\n",
    "    if rating in ['AAA', 'AA+', 'AA', 'AA-']:\n",
    "        return 'High Grade'\n",
    "    elif rating in ['A+', 'A', 'A-', 'BBB+', 'BBB', 'BBB-']:\n",
    "        return 'Medium Grade'\n",
    "    elif rating in ['BB+', 'BB', 'BB-', 'B+', 'B', 'B-']:\n",
    "        return 'Speculative'\n",
    "    else:\n",
    "        return 'High Risk'\n",
    "\n",
    "results_df['Rating_Category'] = results_df['Credit_Rating_Label'].apply(rating_to_category)\n",
    "\n",
    "# Cross-tabulation\n",
    "crosstab = pd.crosstab(results_df['Cluster'], results_df['Rating_Category'])\n",
    "print(\"Cross-Tabulation: Cluster vs Rating Category\")\n",
    "print(\"=\"*80)\n",
    "print(crosstab)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-tabulation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(crosstab, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Count'})\n",
    "plt.title(f'K-Means Clusters vs Credit Rating Categories (K={optimal_k})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Rating Category', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Cluster', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_cluster = LabelEncoder()\n",
    "le_rating = LabelEncoder()\n",
    "\n",
    "clusters_encoded = le_cluster.fit_transform(results_df['Cluster'])\n",
    "ratings_encoded = le_rating.fit_transform(results_df['Rating_Category'])\n",
    "\n",
    "ari = adjusted_rand_score(ratings_encoded, clusters_encoded)\n",
    "nmi = normalized_mutual_info_score(ratings_encoded, clusters_encoded)\n",
    "\n",
    "print(\"Similarity Metrics:\")\n",
    "print(f\"  Adjusted Rand Index (ARI): {ari:.4f}\")\n",
    "print(f\"  Normalized Mutual Information (NMI): {nmi:.4f}\")\n",
    "print()\n",
    "\n",
    "if ari > 0.6:\n",
    "    interpretation = 'Strong correspondence'\n",
    "elif ari > 0.3:\n",
    "    interpretation = 'Moderate correspondence'\n",
    "else:\n",
    "    interpretation = 'Weak correspondence'\n",
    "\n",
    "print(f\"Interpretation: {interpretation} ({ari:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers (countries in unexpected clusters)\n",
    "outliers = []\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = results_df[results_df['Cluster'] == cluster_id]\n",
    "    rating_counts = cluster_data['Rating_Category'].value_counts()\n",
    "    \n",
    "    if len(rating_counts) > 0:\n",
    "        dominant_category = rating_counts.index[0]\n",
    "        mismatched = cluster_data[cluster_data['Rating_Category'] != dominant_category]\n",
    "        \n",
    "        for _, row in mismatched.iterrows():\n",
    "            outliers.append({\n",
    "                'Country': row['Country'],\n",
    "                'Year': row['Year'],\n",
    "                'Rating': row['Credit_Rating_Label'],\n",
    "                'Rating_Category': row['Rating_Category'],\n",
    "                'Cluster': cluster_id,\n",
    "                'Expected_Category': dominant_category,\n",
    "                'Silhouette_Score': row['Silhouette_Score']\n",
    "            })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers)\n",
    "outliers_df = outliers_df.sort_values('Silhouette_Score')\n",
    "\n",
    "print(f\"Top 20 Outliers (lowest silhouette scores):\")\n",
    "print(\"=\"*80)\n",
    "print(outliers_df.head(20).to_string(index=False))\n",
    "print(f\"\\nTotal outliers detected: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. PCA Visualization (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA (8D → 2D)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "variance_explained = pca.explained_variance_ratio_\n",
    "print(f\"PCA Variance Explained:\")\n",
    "print(f\"  PC1: {variance_explained[0]:.1%}\")\n",
    "print(f\"  PC2: {variance_explained[1]:.1%}\")\n",
    "print(f\"  Total: {variance_explained.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in 2D\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Colored by Cluster\n",
    "scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, \n",
    "                           cmap='viridis', s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add cluster centers\n",
    "centers_pca = pca.transform(kmeans.cluster_centers_)\n",
    "axes[0].scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "               c='red', marker='*', s=500, edgecolors='black', linewidth=2,\n",
    "               label='Cluster Centers')\n",
    "\n",
    "axes[0].set_xlabel(f'PC1 ({variance_explained[0]:.1%} variance)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel(f'PC2 ({variance_explained[1]:.1%} variance)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('K-Means Clusters (PCA 2D)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# Plot 2: Colored by Rating\n",
    "rating_order = ['CCC-', 'CCC', 'CCC+', 'CC', 'B-', 'B', 'B+', \n",
    "               'BB-', 'BB', 'BB+', 'BBB-', 'BBB', 'BBB+',\n",
    "               'A-', 'A', 'A+', 'AA-', 'AA', 'AA+', 'AAA']\n",
    "\n",
    "def rating_to_numeric(rating):\n",
    "    try:\n",
    "        return rating_order.index(rating)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "ratings_numeric = results_df['Credit_Rating_Label'].apply(rating_to_numeric).values\n",
    "scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=ratings_numeric,\n",
    "                          cmap='RdYlGn', s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "axes[1].set_xlabel(f'PC1 ({variance_explained[0]:.1%} variance)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel(f'PC2 ({variance_explained[1]:.1%} variance)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Credit Ratings (PCA 2D)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(scatter2, ax=axes[1], label='Rating')\n",
    "cbar.set_label('Rating (Low → High)', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    cluster_silhouette_vals = silhouette_vals[clusters == i]\n",
    "    cluster_silhouette_vals.sort()\n",
    "    \n",
    "    size_cluster_i = cluster_silhouette_vals.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "    color = plt.cm.viridis(float(i) / optimal_k)\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, cluster_silhouette_vals,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    \n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.set_xlabel('Silhouette Coefficient', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Cluster', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Silhouette Plot (K={optimal_k})', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=silhouette, color='red', linestyle='--', label=f'Average: {silhouette:.4f}')\n",
    "ax.legend()\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim([-0.3, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Insights and Conclusions\n",
    "\n",
    "### Summary of Findings:\n",
    "\n",
    "1. **Optimal Number of Clusters**: K-Means identified **K=3** as optimal based on silhouette score\n",
    "\n",
    "2. **Cluster Characteristics**:\n",
    "   - **Cluster 0**: Medium risk profile (largest group)\n",
    "   - **Cluster 1**: Low risk profile (stable economies)\n",
    "   - **Cluster 2**: High risk profile (high inflation/interest rates)\n",
    "\n",
    "3. **Correspondence with Credit Ratings**: \n",
    "   - ARI score indicates **weak correspondence** (~7%)\n",
    "   - This suggests credit ratings incorporate factors beyond macroeconomic indicators\n",
    "   - Qualitative factors (political stability, institutions, etc.) play a significant role\n",
    "\n",
    "4. **Outliers**: \n",
    "   - Several countries show economic profiles inconsistent with their ratings\n",
    "   - These may represent:\n",
    "     - Recent economic changes not yet reflected in ratings\n",
    "     - Special circumstances (e.g., natural resources, geopolitical factors)\n",
    "     - Rating agency subjective judgment\n",
    "\n",
    "5. **Comparison with Supervised Learning**:\n",
    "   - Random Forest (Phase 2): 79.68% accuracy → Can predict ratings from features\n",
    "   - K-Means (Phase 3): 7% ARI → Natural groups ≠ rating categories\n",
    "   - **Insight**: Ratings are predictable but not based on simple economic similarity\n",
    "\n",
    "### Implications:\n",
    "\n",
    "- Credit ratings are **complex, non-linear functions** of economic indicators\n",
    "- Simple clustering cannot replicate rating agency decisions\n",
    "- Machine learning models (Random Forest) can learn these complex patterns\n",
    "- Unsupervised learning reveals that economic similarity ≠ credit risk similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Load Saved Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved clustering results\n",
    "cluster_profiles = pd.read_csv('../results/clustering/cluster_profiles.csv')\n",
    "country_clusters = pd.read_csv('../results/clustering/country_clusters.csv')\n",
    "\n",
    "print(\"Cluster Profiles:\")\n",
    "print(cluster_profiles)\n",
    "print(\"\\nCountry Clusters (sample):\")\n",
    "print(country_clusters.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
